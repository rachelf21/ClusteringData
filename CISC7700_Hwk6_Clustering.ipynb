{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traverseFiles(directory, articles):\n",
    "    i=0\n",
    "    rootDir = directory\n",
    "    print(\"Reading files...\")\n",
    "    for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "        sentences = []\n",
    "        for fname in fileList:\n",
    "            story=\"\"\n",
    "            if fname==\"index.html\":\n",
    "                i=i+1\n",
    "                #print(i, \"\\t%s\" % fname)\n",
    "                file = open(dirName+\"\\\\\"+fname, \"rb\")      \n",
    "                contents= file.read()  \n",
    "                soup = BeautifulSoup(contents, \"html.parser\") \n",
    "                titleText = soup.title.string\n",
    "                sentences.append(titleText)\n",
    "                sentences.append(titleText)\n",
    "                articleText = soup.find_all(\"div\",{\"class\": \"zn-body__paragraph\"})\n",
    "                for p in articleText:\n",
    "                    sentences.append(p.get_text())\n",
    "                    story=\"\".join(sentences)\n",
    "                articles.append(story)\n",
    "    print(i , \"articles processed\\n\\n\\n\")\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "3049 articles processed\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reading articles\n",
    "articles_train=[]\n",
    "articles_train = traverseFiles(\"C:\\\\Users\\\\Rachel\\\\Downloads\\\\cnn\\\\www.cnn.com\", articles_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "245 articles processed\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reading test articles\n",
    "articles_test=[]\n",
    "articles_test = traverseFiles(\"C:\\\\Users\\\\Rachel\\\\Documents\\\\Data Science\\\\2015\", articles_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster:  0\n",
      "buttigieg\n",
      "davis\n",
      "bend\n",
      "biden\n",
      "south\n",
      "black\n",
      "voters\n",
      "poll\n",
      "politico\n",
      "support\n",
      "\n",
      "Cluster:  1\n",
      "trump\n",
      "president\n",
      "china\n",
      "white\n",
      "obama\n",
      "facts\n",
      "tariffs\n",
      "administration\n",
      "iran\n",
      "trade\n",
      "\n",
      "Cluster:  2\n",
      "women\n",
      "children\n",
      "police\n",
      "school\n",
      "health\n",
      "court\n",
      "family\n",
      "climate\n",
      "government\n",
      "president\n",
      "\n",
      "Cluster:  3\n",
      "sleep\n",
      "science\n",
      "wake\n",
      "infant\n",
      "brain\n",
      "quiz\n",
      "light\n",
      "night\n",
      "depression\n",
      "dr\n",
      "\n",
      "Cluster:  4\n",
      "biden\n",
      "trump\n",
      "buttigieg\n",
      "debate\n",
      "democratic\n",
      "joe\n",
      "warren\n",
      "voters\n",
      "president\n",
      "sanders\n",
      "\n",
      "Cluster:  5\n",
      "kong\n",
      "hong\n",
      "protesters\n",
      "china\n",
      "police\n",
      "chinese\n",
      "protests\n",
      "city\n",
      "campus\n",
      "trade\n",
      "\n",
      "Cluster:  6\n",
      "trump\n",
      "impeachment\n",
      "president\n",
      "house\n",
      "mueller\n",
      "ukraine\n",
      "democrats\n",
      "sondland\n",
      "republicans\n",
      "testimony\n",
      "\n",
      "Cluster:  7\n",
      "parnas\n",
      "fruman\n",
      "giuliani\n",
      "trump\n",
      "nunes\n",
      "donations\n",
      "prosecutors\n",
      "ukraine\n",
      "campaign\n",
      "campaigns\n",
      "\n",
      "Cluster:  8\n",
      "delhi\n",
      "pollution\n",
      "smog\n",
      "air\n",
      "india\n",
      "city\n",
      "polluted\n",
      "diwali\n",
      "kejriwal\n",
      "burning\n",
      "\n",
      "Cluster:  9\n",
      "puerto\n",
      "rico\n",
      "hurricane\n",
      "maria\n",
      "deaths\n",
      "storm\n",
      "fema\n",
      "death\n",
      "toll\n",
      "funeral\n"
     ]
    }
   ],
   "source": [
    "#%% Running TFIDF and KMeans\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union([\"states\", \"need\",  \"study\",  \"000\", \"work\",  \"comment\", \"2018\", \"said\", \"don\", \"new\", \"life\", \"company\", \"state\", \"says\", \"knew\", \"make\", \"say\", \"used\", \"world\", \"know\", \"day\" , \"time\" , \"tells\", \"related\", \"sixth\", \"ruled\", \"like\", \"yes\", \"rose\", \"jr\", \"week\", \"11\", \"reads\",\"way\", \"york\", \"laugh\", \"wrote\", \"views\", \"just\", \"told\", \"people\", \"year\", \"years\", \"according\", \"cnn\", \"did\"])\n",
    "vectorizer = TfidfVectorizer(stop_words=my_stop_words, ngram_range = (1,1), min_df=5 , max_df=.5) #\n",
    "X = vectorizer.fit_transform(articles_train)\n",
    "\n",
    "true_k = 10\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', random_state=5, max_iter=300, n_init=10)#\n",
    "model.fit_predict(X)\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(true_k):\n",
    "   print(\"\\nCluster: \" , i)\n",
    "   for ind in order_centroids[i, :10]:\n",
    "        print(terms[ind])\n",
    "        \n",
    "clusters = model.labels_.tolist()\n",
    "#print(\"********Clusters: \" , clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning Clusters to Test Documents:\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 3 3 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "#% TESTING PREDICTION \n",
    "print(\"Assigning Clusters to Test Documents:\")\n",
    "Y = vectorizer.transform(articles_test)\n",
    "predicted=model.predict(Y)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
